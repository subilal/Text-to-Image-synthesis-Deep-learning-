{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import tensorlayer as tl\n",
    "from utils import *\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorlayer.layers import *\n",
    "from tensorlayer.prepro import *\n",
    "from tensorlayer.cost import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"1 : cwd \" + cwd)\n",
    "img_dir = os.path.join(cwd, 'CUB\\\\images')\n",
    "print(\"1 : img_dir \" + img_dir)\n",
    "\n",
    "caption_dir = os.path.join(cwd, 'birds\\\\text_c10')\n",
    "print(\"1 : caption_dir \" + caption_dir)\n",
    "\n",
    "VOC_FIR = cwd + '\\\\vocab.txt'\n",
    "print(\"1 : VOC_FIR \" + VOC_FIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load captions\n",
    "caption_sub_dir = load_folder_list( caption_dir )\n",
    "caption_sub_dir\n",
    "captions_dict = {}\n",
    "processed_capts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 16\n",
    "z_dim = 1024          #### changed 1024 <------ 512 \n",
    "image_size = 256    \n",
    "c_dim = 3          \n",
    "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"_vocab.pickle\", 'rb') as f:\n",
    "     vocab = pickle.load(f)\n",
    "with open(\"_image_train.pickle\", 'rb') as f:\n",
    "     images_train,_ = pickle.load(f)\n",
    "with open(\"_image_test.pickle\", 'rb') as f:\n",
    "     images_test,_ = pickle.load(f)\n",
    "with open(\"_n.pickle\", 'rb') as f:\n",
    "     n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test = pickle.load(f)\n",
    "with open(\"_caption.pickle\", 'rb') as f:\n",
    "     captions_ids_train, captions_ids_test = pickle.load(f)\n",
    "\n",
    "        \n",
    "print(len(images_train))\n",
    "print(len(images_train[0]))\n",
    "print(len(images_train[1]))\n",
    "print(len(images_train[2]))\n",
    "print(len(images_train[3]))\n",
    "print(len(images_train[0][0]))\n",
    "print(len(images_train[0][0][0]))\n",
    "\n",
    "print(type(images_train))\n",
    "print(type(images_train[0]))\n",
    "print(type(images_train[0][0]))\n",
    "print(type(images_train[0][0][0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "images_train = np.array(images_train).astype(np.float32)\n",
    "images_test = np.array(images_test)\n",
    "ni = int(np.ceil(np.sqrt(batch_size)))\n",
    "\n",
    "\n",
    "print(len(images_train))\n",
    "print(len(images_train[0]))\n",
    "print(len(images_train[0][0]))\n",
    "print(len(images_train[0][0][0]))\n",
    "\n",
    "print(type(images_train))\n",
    "print(type(images_train[0]))\n",
    "print(type(images_train[0][0]))\n",
    "print(type(images_train[0][0][0]))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(\"samples/step1_gan-cls\"):\n",
    "    os.makedirs(\"samples/step1_gan-cls\")\n",
    "if not os.path.exists(\"samples/step_pretrain_encoder\"):\n",
    "    os.makedirs(\"samples/step_pretrain_encoder\")        \n",
    "if not os.path.exists(\"checkpoint\"):\n",
    "    os.makedirs(\"checkpoint\")\n",
    "save_dir = \"checkpoint\"\n",
    "\n",
    "\n",
    "w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "df_dim = 64\n",
    "inputs = []\n",
    "## for text-to-image mapping ===================================================\n",
    "t_dim = 256         # text feature dimension # changed 256 <---- 128\n",
    "rnn_hidden_size = t_dim\n",
    "vocab_size = 8000\n",
    "word_embedding_size = 256\n",
    "keep_prob = 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def cnn_encoder(inputs, is_train=True, reuse=False, name='cnnftxt', return_h3=False):\n",
    "    \"\"\" 64x64 --> t_dim, for text-image mapping \"\"\"\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    df_dim = 256\n",
    "\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        tl.layers.set_name_reuse(tf.AUTO_REUSE)\n",
    "\n",
    "        net_in = InputLayer(inputs, name='/in')\n",
    "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                padding='SAME', W_init=w_init, name='cnnf/h0/conv2d')\n",
    "\n",
    "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h1/conv2d')\n",
    "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h1/batch_norm')\n",
    "\n",
    "        # if name != 'cnn': # debug for training image encoder in step 2\n",
    "        #     net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, name='p/h1/drop')\n",
    "\n",
    "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h2/conv2d')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h2/batch_norm')\n",
    "\n",
    "        # if name != 'cnn': # debug for training image encoder in step 2\n",
    "        #     net_h2 = DropoutLayer(net_h2, keep=0.8, is_fix=True, name='p/h2/drop')\n",
    "\n",
    "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h3/conv2d')\n",
    "        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h3/batch_norm')\n",
    "\n",
    "        # if name != 'cnn': # debug for training image encoder in step 2\n",
    "        #     net_h3 = DropoutLayer(net_h3, keep=0.8, is_fix=True, name='p/h3/drop')\n",
    "\n",
    "        net_h4 = FlattenLayer(net_h3, name='cnnf/h4/flatten')\n",
    "        net_h4 = DenseLayer(net_h4, n_units= (z_dim if name == 'z_encoder' else t_dim),\n",
    "                act=tf.identity,\n",
    "                W_init = w_init, b_init = None, name='cnnf/h4/embed')\n",
    "    if return_h3:\n",
    "        return net_h4, net_h3\n",
    "    else:\n",
    "        return net_h4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rnn_embed(input_seqs, is_train=True, reuse=False, return_embed=False):\n",
    "    \"\"\" txt --> t_dim \"\"\"\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    if tf.__version__ <= '0.12.1':\n",
    "        LSTMCell = tf.nn.rnn_cell.LSTMCell\n",
    "    else:\n",
    "        LSTMCell = tf.contrib.rnn.BasicLSTMCell\n",
    "    with tf.variable_scope(\"rnnftxt\", reuse=tf.AUTO_REUSE):\n",
    "        tl.layers.set_name_reuse(True)\n",
    "        network = EmbeddingInputlayer(\n",
    "                     inputs = input_seqs,\n",
    "                     vocabulary_size = vocab_size,\n",
    "                     embedding_size = word_embedding_size,\n",
    "                     E_init = w_init,\n",
    "                     name = 'rnn/wordembed')\n",
    "        network = DynamicRNNLayer(network,\n",
    "                     cell_fn = LSTMCell,\n",
    "                     cell_init_args = {'state_is_tuple' : True, 'reuse': reuse},  # for TF1.1, TF1.2 dont need to set reuse\n",
    "                     n_hidden = rnn_hidden_size,\n",
    "                     dropout = (keep_prob if is_train else None),\n",
    "                     initializer = w_init,\n",
    "                     sequence_length = tl.layers.retrieve_seq_length_op2(input_seqs),\n",
    "                     return_last = True,\n",
    "                     name = 'rnn/dynamic')\n",
    "        return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discriminator_txt2img_resnet(input_images, t_txt=None, is_train=True, reuse=False):\n",
    "    \"\"\" 64x64 + (txt) --> real/fake \"\"\"\n",
    "    # https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py\n",
    "    # Discriminator with ResNet : line 197 https://github.com/reedscot/icml2016/blob/master/main_cls.lua\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    gamma_init=tf.random_normal_initializer(1., 0.02)\n",
    "    df_dim = 64  # 64 for flower, 196 for MSCOCO\n",
    "    s = 256 # output image size [64]\n",
    "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "    \n",
    "\n",
    "    with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "        tl.layers.set_name_reuse(True)\n",
    "        net_in = InputLayer(input_images, name='d_input/images')\n",
    "        print(\"1   \",net_in.outputs.shape )\n",
    "    \n",
    "        net_h0 = Conv2d(net_in, df_dim, (4, 4),(2,2), act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                padding='SAME', W_init=w_init, name='d_h0/conv2d')\n",
    "        \n",
    "        \n",
    "        print(\"2   \",net_h0.outputs.shape )\n",
    "        \n",
    "        \n",
    "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2,2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h1/conv2d')\n",
    "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h1/batchnorm')\n",
    "        \n",
    "        \n",
    "        print(\"3   \",net_h1.outputs.shape )\n",
    "        \n",
    "        \n",
    "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2,2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h2/conv2d')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h2/batchnorm')\n",
    "        \n",
    "        \n",
    "        print(\"3.1   \",net_h2.outputs.shape )\n",
    "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h3/conv2d') # new co\n",
    "        \n",
    "        net_h3_1 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h3/batchnorm')\n",
    "        \n",
    "        \n",
    "        print(\"4.1  \",net_h3_1.outputs.shape )\n",
    "        \n",
    "        \n",
    "        net_h3 = Conv2d(net_h3_1, df_dim*16, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h311/conv2dd')\n",
    "        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h311/batchnormmm')\n",
    "        print(\"5  \",net_h3.outputs.shape )\n",
    "        \n",
    "        net_h3 = Conv2d(net_h3, df_dim*32, (4, 4), (2, 2), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h322/conv2ddd')\n",
    "        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h322/batchnormmmm')\n",
    "        print(\"6  \",net_h3.outputs.shape )\n",
    "        \n",
    "        \n",
    "        \n",
    "        net1 = Conv2d(net_h3, df_dim*16, (1, 1), (1, 1), act=None,\n",
    "                padding='VALID', W_init=w_init, b_init=None, name='d_h4_res0/0conv2d')\n",
    "        net1 = BatchNormLayer(net1, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res0/0batchnorm')\n",
    "        \n",
    "        print(\"6.1  \",net1.outputs.shape )\n",
    "        net2 = Conv2d(net1, df_dim*8, (1, 1), (1, 1), act=None,\n",
    "                padding='VALID', W_init=w_init, b_init=None, name='d_h4_res1/1conv2d')\n",
    "        net2 = BatchNormLayer(net2, #act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res1/1batchnorm')# code old add\n",
    "        print(\"6.2  \",net2.outputs.shape )\n",
    "        \n",
    "        print(\"6.3  \",net1.outputs.shape )\n",
    "        net3 = Conv2d(net2, df_dim*2, (1, 1), (1, 1), act=None,\n",
    "                padding='VALID', W_init=w_init, b_init=None, name='d_h4_res10/10conv2d')\n",
    "        net3 = BatchNormLayer(net3, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res10/10batchnorm')\n",
    "        print(\"6.3  \",net2.outputs.shape )\n",
    "    \n",
    "    \n",
    "                \n",
    "            \n",
    "        net = Conv2d(net3, df_dim*2, (3, 3), (1, 1), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d2')\n",
    "        net = BatchNormLayer(net, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm2')\n",
    "        print(\"8  \",net.outputs.shape )\n",
    "        \n",
    "        \n",
    "        net = Conv2d(net, df_dim*8, (3, 3), (1, 1), act=None,\n",
    "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d3')\n",
    "        net = BatchNormLayer(net, #act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm3')\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"9  \",net.outputs.shape )\n",
    "        net_h4 = ElementwiseLayer(layer=[net2, net], combine_fn=tf.add, name='d_h4/add')\n",
    "        net_h4.outputs = tl.act.lrelu(net_h4.outputs, 0.2)\n",
    "        print(\"10 \",net_h4.outputs.shape )\n",
    "\n",
    "        if t_txt is not None:\n",
    "            net_txt = InputLayer(t_txt, name='d_input_txt')\n",
    "            net_txt = DenseLayer(net_txt, n_units=t_dim,\n",
    "                   act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                   W_init=w_init, name='d_reduce_txt/dense')\n",
    "            print(\"DA \",net_txt.outputs.shape )\n",
    "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim1')\n",
    "            print(\"DA  da \",net_txt.outputs.shape )\n",
    "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim2')\n",
    "            print(\"DA da da \",net_txt.outputs.shape )\n",
    "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\n",
    "            print(\"DA da da da\",net_txt.outputs.shape )\n",
    "            print(\"DA da da da\",net_h4.outputs.shape )\n",
    "            \n",
    "            \n",
    "            net_h4_concat = ConcatLayer([net_h4, net_txt], concat_dim=3, name='d_h3_concat')\n",
    "            # 243 (ndf*8 + 128 or 256) x 4 x 4\n",
    "            print(\"DA 111 \",net_h4_concat.outputs.shape )\n",
    "            net_ho = Conv2d(net_h4_concat, df_dim*8, (1, 1), (1, 1),\n",
    "                    padding='VALID', W_init=w_init, b_init=None, name='d_h3/conv2d_2')\n",
    "            net_ho = BatchNormLayer(net_ho, act=lambda x: tl.act.lrelu(x, 0.2),\n",
    "                    is_train=is_train, gamma_init=gamma_init, name='d_h3/batch_norm_2')\n",
    "            print(\"DA 111 2222 \",net_ho.outputs.shape )\n",
    "            \n",
    "           \n",
    "\n",
    "        #net_ho = Conv2d(net_h4, 1, (s16, s16), (s16, s16), padding='VALID', W_init=w_init, name='d_hop/pconv2d')\n",
    "\n",
    "        net_ho = FlattenLayer(net_ho, name='d_hop/pflatten')\n",
    "        logits = net_ho.outputs\n",
    "        net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\n",
    "    return net_ho, logits        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator_txt2img_resnet(input_z, t_txt=None, is_train=True, reuse=False, batch_size=batch_size):\n",
    "    \"\"\" z + (txt) --> 64x64 \"\"\"\n",
    "    # https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py\n",
    "    s = 64 # output image size [64]\n",
    "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "    gf_dim = 128\n",
    "\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "        tl.layers.set_name_reuse(True)\n",
    "        net_in = InputLayer(input_z, name='g_inputz')\n",
    "        print(\" 1 \",net_in.outputs.shape)\n",
    "\n",
    "        if t_txt is not None:\n",
    "            net_txt = InputLayer(t_txt, name='g_input_txt')\n",
    "            print(\" 2 \",net_txt.outputs.shape)\n",
    "            net_txt = DenseLayer(net_txt, n_units=t_dim,\n",
    "                act=lambda x: tl.act.lrelu(x, 0.2), W_init=w_init, name='g_reduce_text/dense')\n",
    "            print(\" 3 \",net_txt.outputs.shape)\n",
    "            net_in = ConcatLayer([net_in, net_txt], concat_dim=1, name='g_concat_z_txt')\n",
    "            print(\" 4 \",net_in.outputs.shape)\n",
    "\n",
    "        net_h0 = DenseLayer(net_in, gf_dim*8*4*4, act=tf.nn.relu,\n",
    "                W_init=w_init, b_init=None, name='g_h0/dense')\n",
    "        print(\" 5 \",net_h0.outputs.shape)\n",
    "        net_h0 = BatchNormLayer(net_h0,  #act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h0/batch_norm')\n",
    "        net_h0 = ReshapeLayer(net_h0, [-1, 4, 4, gf_dim*8], name='g_h0/reshape')\n",
    "        print(\" 6 \",net_h0.outputs.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#         net = Conv2d(net_h0, gf_dim*2, (1, 1), (1, 1),\n",
    "#                 padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d')\n",
    "#         net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\n",
    "#                 gamma_init=gamma_init, name='g_h1_res/batch_norm')\n",
    "#         print(\" 7 \",net.outputs.shape)\n",
    "        \n",
    "#         net = Conv2d(net, gf_dim*2, (3, 3), (1, 1),\n",
    "#                 padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d2')\n",
    "#         net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\n",
    "#                 gamma_init=gamma_init, name='g_h1_res/batch_norm2')\n",
    "#         print(\" 8 \",net.outputs.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         net = Conv2d(net, gf_dim*8, (3, 3), (1, 1),\n",
    "#                 padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d3')\n",
    "#         net = BatchNormLayer(net, # act=tf.nn.relu,\n",
    "#                 is_train=is_train, gamma_init=gamma_init, name='g_h1_res/batch_norm3')\n",
    "#         print(\" 9 \",net.outputs.shape)\n",
    "#         net_h1 = ElementwiseLayer(layer=[net_h0, net], combine_fn=tf.add, name='g_h1_res/add')\n",
    "#         net_h1.outputs = tf.nn.relu(net_h1.outputs)\n",
    "#         print(\" 10 \",net_h1.outputs.shape)\n",
    "\n",
    "        # Note: you can also use DeConv2d to replace UpSampling2dLayer and Conv2d\n",
    "        # net_h2 = DeConv2d(net_h1, gf_dim*4, (4, 4), out_size=(s8, s8), strides=(2, 2),\n",
    "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h2/decon2d')\n",
    "        net_h2 = UpSampling2dLayer(net_h0, size=[8, 8], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h2/upsample2d')\n",
    "        net_h2 = Conv2d(net_h2, 512, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h2/conv2d')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h2/batch_norm')\n",
    "        print(\" up1  \",net_h2.outputs.shape)\n",
    "        \n",
    "        net_h2 = UpSampling2dLayer(net_h2, size=[16, 16], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h2/upsample2d')\n",
    "        net_h2 = Conv2d(net_h2, 256, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h21/conv2d1')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h21/batch_norm1')\n",
    "        print(\" up2  \",net_h2.outputs.shape)\n",
    "        \n",
    "        net_h2 = UpSampling2dLayer(net_h2, size=[32, 32], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h2/upsample2d')\n",
    "        net_h2 = Conv2d(net_h2, 128, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h22/conv2d2')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h22/batch_norm2')\n",
    "        print(\" up3  \",net_h2.outputs.shape)\n",
    "        \n",
    "        net_h2 = UpSampling2dLayer(net_h2, size=[64, 64], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h2/upsample2d')\n",
    "        net_h2 = Conv2d(net_h2,64, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h23/conv2d3')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h23/batch_norm3')\n",
    "        print(\" up4  \",net_h2.outputs.shape)\n",
    "        \n",
    "        \n",
    "        net_ho = Conv2d(net_h2, c_dim, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, name='g_h4/conv2d4')\n",
    "        print(\" up1  \",net_ho.outputs.shape)\n",
    "        \n",
    "        net_ho.outputs = tf.nn.tanh(net_ho.outputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        net_h3 = Conv2d(net_ho, 128, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, name='g_h6/conv2d6')\n",
    "      \n",
    "        net_h3.outputs = tf.nn.relu(net_h3.outputs)\n",
    "        print(\" zero conv  \",net_h3.outputs.shape)\n",
    "        \n",
    "        \n",
    "        net_h3 = Conv2d(net_h3, 256, (4, 4), (2, 2),\n",
    "                padding='SAME', act=None, W_init=w_init, name='g_h7/conv2d7')\n",
    "      \n",
    "        net_h3.outputs = tf.nn.relu(net_h3.outputs)\n",
    "        print(\" zero two  \",net_h3.outputs.shape)\n",
    "        \n",
    "        net_h3 = Conv2d(net_h3, 512, (4, 4), (2, 2),\n",
    "                padding='SAME', act=None, W_init=w_init, name='g_h8/conv2d8')\n",
    "      \n",
    "        net_h3.outputs = tf.nn.relu(net_h3.outputs)\n",
    "        print(\" zero three  \",net_h3.outputs.shape)\n",
    "        \n",
    "        \n",
    "        net_E = ExpandDimsLayer(net_h3, 1, name='g_h9/expanddim9')\n",
    "        net_E = ExpandDimsLayer(net_E, 1, name='g_h9/expanddim10')\n",
    "        net_E = TileLayer(net_E, [1, 16, 16, 1], name='g_h9/tile9')\n",
    "        net_E = ConcatLayer([net_E, net_txt], concat_dim=3, name='10/g_h9d_h10')\n",
    "        print(\" zero four  \",net_E.outputs.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#         net = Conv2d(net_h2, gf_dim, (1, 1), (1, 1),\n",
    "#                 padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d')\n",
    "#         net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\n",
    "#                 gamma_init=gamma_init, name='g_h3_res/batch_norm')\n",
    "#         net = Conv2d(net, gf_dim, (3, 3), (1, 1),\n",
    "#                 padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d2')\n",
    "#         net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\n",
    "#                 gamma_init=gamma_init, name='g_h3_res/batch_norm2')\n",
    "#         net = Conv2d(net, gf_dim*4, (3, 3), (1, 1),\n",
    "#                 padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d3')\n",
    "#         net = BatchNormLayer(net, #act=tf.nn.relu,\n",
    "#                 is_train=is_train, gamma_init=gamma_init, name='g_h3_res/batch_norm3')\n",
    "#         net_h3 = ElementwiseLayer(layer=[net_h2, net], combine_fn=tf.add, name='g_h3/add')\n",
    "#         net_h3.outputs = tf.nn.relu(net_h3.outputs)\n",
    "#         print(\" 11 \",net_h3.outputs.shape)\n",
    "        # net_h4 = DeConv2d(net_h3, gf_dim*2, (4, 4), out_size=(s4, s4), strides=(2, 2),\n",
    "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h4/decon2d'),\n",
    "        net_h4 = UpSampling2dLayer(net_h3, size=[s8, s8], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h4/upsample2d')\n",
    "        net_h4 = Conv2d(net_h4, gf_dim*2, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h4/conv2d')\n",
    "        net_h4 = BatchNormLayer(net_h4, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h4/batch_norm')\n",
    "        print(\" 12 \",net_h4.outputs.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #====================================================================================\n",
    "        \n",
    "        net_h4 = UpSampling2dLayer(net_h4, size=[s4, s4], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h4d/dupsample2d')\n",
    "        net_h4 = Conv2d(net_h4, gf_dim*2, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h4d/dconv2d')\n",
    "        net_h4 = BatchNormLayer(net_h4, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h4d/dbatch_norm')\n",
    "        print(\" 20 \",net_h4.outputs.shape)\n",
    "        \n",
    "#         net_h4 = UpSampling2dLayer(net_h4, size=[s2, s2], is_scale=False, method=1,\n",
    "#                 align_corners=False, name='g_h4f/fupsample2d')\n",
    "#         net_h4 = Conv2d(net_h4, gf_dim*2, (3, 3), (1, 1),\n",
    "#                 padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h4f/fconv2d')\n",
    "#         net_h4 = BatchNormLayer(net_h4, act=tf.nn.relu,\n",
    "#                 is_train=is_train, gamma_init=gamma_init, name='g_h4f/fbatch_norm')\n",
    "#         print(\" 22 \",net_h4.outputs.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #=======================================================================================\n",
    "        # net_h5 = DeConv2d(net_h4, gf_dim, (4, 4), out_size=(s2, s2), strides=(2, 2),\n",
    "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h5/decon2d')\n",
    "        net_h5 = UpSampling2dLayer(net_h4, size=[s2, s2], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_h5/upsample2d')\n",
    "        net_h5 = Conv2d(net_h5, gf_dim, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h5/conv2d')\n",
    "        net_h5 = BatchNormLayer(net_h5, act=tf.nn.relu,\n",
    "                is_train=is_train, gamma_init=gamma_init, name='g_h5/batch_norm')\n",
    "        print(\" 12 \",net_h5.outputs.shape)\n",
    "        # net_ho = DeConv2d(net_h5, c_dim, (4, 4), out_size=(s, s), strides=(2, 2),\n",
    "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, name='g_ho/decon2d')\n",
    "        net_ho = UpSampling2dLayer(net_h5, size=[s, s], is_scale=False, method=1,\n",
    "                align_corners=False, name='g_ho/upsample2d')\n",
    "        net_ho = Conv2d(net_ho, c_dim, (3, 3), (1, 1),\n",
    "                padding='SAME', act=None, W_init=w_init, name='g_ho/conv2d')\n",
    "        \n",
    "        print(\" 13 \",net_h5.outputs.shape)\n",
    "        logits = net_ho.outputs\n",
    "        net_ho.outputs = tf.nn.tanh(net_ho.outputs)\n",
    "        print(\" outputs  \",net_ho.outputs.shape)\n",
    "    return net_ho, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_real_image = tf.placeholder('float32', [batch_size, image_size, image_size, 3], name = 'real_image')\n",
    "print(t_real_image.shape)\n",
    "t_wrong_image = tf.placeholder('float32', [batch_size ,image_size, image_size, 3], name = 'wrong_image')\n",
    "print(t_wrong_image.shape)\n",
    "t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\n",
    "print(t_real_caption.shape)\n",
    "t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='wrong_caption_input')\n",
    "print(t_wrong_caption.shape)\n",
    "t_z = tf.placeholder(tf.float32, [batch_size, z_dim], name='z_noise')\n",
    "print(t_z.shape)\n",
    "\n",
    "## training inference for text-to-image mapping\n",
    "net_cnn = cnn_encoder(t_real_image, is_train=True, reuse=False)\n",
    "x = net_cnn.outputs\n",
    "v = rnn_embed(t_real_caption, is_train=True, reuse=False).outputs\n",
    "x_w = cnn_encoder(t_wrong_image, is_train=True, reuse=True).outputs\n",
    "v_w = rnn_embed(t_wrong_caption, is_train=True, reuse=True).outputs\n",
    "\n",
    "alpha = 0.2 # margin alpha\n",
    "rnn_loss = tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "            tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "\n",
    "## training inference for txt2img\n",
    "generator_txt2img = generator_txt2img_resnet\n",
    "discriminator_txt2img = discriminator_txt2img_resnet\n",
    "\n",
    "net_rnn = rnn_embed(t_real_caption, is_train=False, reuse=True)\n",
    "net_fake_image, _ = generator_txt2img(t_z,\n",
    "                net_rnn.outputs,\n",
    "                is_train=True, reuse=False, batch_size=batch_size)\n",
    "                #+ tf.random_normal(shape=net_rnn.outputs.get_shape(), mean=0, stddev=0.02), # NOISE ON RNN\n",
    "net_d, disc_fake_image_logits = discriminator_txt2img(\n",
    "                net_fake_image.outputs, net_rnn.outputs, is_train=True, reuse=False)\n",
    "_, disc_real_image_logits = discriminator_txt2img(\n",
    "                t_real_image, net_rnn.outputs, is_train=True, reuse=True)\n",
    "_, disc_mismatch_logits = discriminator_txt2img(\n",
    "                # t_wrong_image,\n",
    "                t_real_image,\n",
    "                # net_rnn.outputs,\n",
    "                rnn_embed(t_wrong_caption, is_train=False, reuse=True).outputs,\n",
    "                is_train=True, reuse=True)\n",
    "\n",
    "## testing inference for txt2img\n",
    "net_g, _ = generator_txt2img(t_z,\n",
    "                rnn_embed(t_real_caption, is_train=False, reuse=True).outputs,\n",
    "                is_train=False, reuse=True, batch_size=batch_size)\n",
    "\n",
    "d_loss1 = tl.cost.sigmoid_cross_entropy(disc_real_image_logits, tf.ones_like(disc_real_image_logits), name='d1')\n",
    "d_loss2 = tl.cost.sigmoid_cross_entropy(disc_mismatch_logits,  tf.zeros_like(disc_mismatch_logits), name='d2')\n",
    "d_loss3 = tl.cost.sigmoid_cross_entropy(disc_fake_image_logits, tf.zeros_like(disc_fake_image_logits), name='d3')\n",
    "d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "g_loss = tl.cost.sigmoid_cross_entropy(disc_fake_image_logits, tf.ones_like(disc_fake_image_logits), name='g')\n",
    "\n",
    "print(\"Stage 1 sucesss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lr_decay = 0.5      # decay factor for adam, https://github.com/reedscot/icml2016/blob/master/main_cls_int.lua  https://github.com/reedscot/icml2016/blob/master/scripts/train_flowers.sh\n",
    "decay_every = 100   # https://github.com/reedscot/icml2016/blob/master/main_cls.lua\n",
    "beta1 = 0.5\n",
    "\n",
    "cnn_vars = tl.layers.get_variables_with_name('cnn', True, True)\n",
    "rnn_vars = tl.layers.get_variables_with_name('rnn', True, True)\n",
    "d_vars = tl.layers.get_variables_with_name('discriminator', True, True)\n",
    "g_vars = tl.layers.get_variables_with_name('generator', True, True)\n",
    "\n",
    "with tf.variable_scope('learning_rate'):\n",
    "    lr_v = tf.Variable(lr, trainable=False)\n",
    "    d_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(d_loss, var_list=d_vars )\n",
    "    g_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(g_loss, var_list=g_vars )\n",
    "    # e_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(e_loss, var_list=e_vars + c_vars)\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "    optimizer = tf.train.AdamOptimizer(lr_v, beta1=beta1)# optimizer = tf.train.GradientDescentOptimizer(lre)\n",
    "    rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"devima 1\")\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    print(\"devima 1.1\")\n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    ## seed for generation, z and sentence ids\n",
    "    \n",
    "    print(\"devima 2\")\n",
    "    sample_size = batch_size\n",
    "    sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "        # sample_seed = np.random.uniform(low=-1, high=1, size=(sample_size, z_dim)).astype(np.float32)]\n",
    "    n = int(sample_size / ni)\n",
    "    print(\"devima 3\")\n",
    "    sample_sentence = [\"this bird has a bright yellow body, with brown on its crown and wings.\"] * n + \\\n",
    "                      [\"this bird has a red breast and belly as well as a small bill.\"] * n + \\\n",
    "                      [\"small, roundish bird with off white breast and belly, light brown crown, brown and black colored wings.\"] * n + \\\n",
    "                      [\"a white bird with a black crown and yellow beak\"] * n + \\\n",
    "                      [\"the bird has gray crown, belly and white abdomen, with black tarsus and feet\"] * n + \\\n",
    "                      [\"a colorful bird with a bright yellow body, a black crown and throat, orange bill, and black primaries and secondaries.\"] * n + \\\n",
    "                      [\"this bird has wings that are blue and white.\"] * n +\\\n",
    "                      [\"these white bird have wings off white in color and end in a white towards the tips.\"] * n\n",
    "\n",
    "    # sample_sentence = captions_ids_test[0:sample_size]\n",
    "    print(\"devima 3\")\n",
    "    for i, sentence in enumerate(sample_sentence):\n",
    "        print(\"seed: %s\" % sentence)\n",
    "        sentence = preprocess_caption(sentence)\n",
    "        sample_sentence[i] = [vocab[word] for word in nltk.tokenize.word_tokenize(sentence)] + [vocab['</S>']]    # add END_ID\n",
    "        # sample_sentence[i] = [vocab.word_to_id(word) for word in sentence]\n",
    "        # print(sample_sentence[i])\n",
    "    sample_sentence = tl.prepro.pad_sequences(sample_sentence, padding='post')\n",
    "    print(\"devima 4\")\n",
    "    n_epoch = 1000\n",
    "    print_freq = 1\n",
    "    n_batch_epoch = int(n_images_train / batch_size)\n",
    "    print(\"n_batch_epoch\",  n_batch_epoch)\n",
    "    avg_err_d_array =[]\n",
    "    avg_err_g_array =[]\n",
    "    avg_err_r_array =[]\n",
    "    print(\"devima 5\")\n",
    "    # exit()\n",
    "    for epoch in range(0, n_epoch+1):\n",
    "        print(\"devima 6\")\n",
    "        err_d_array =[]\n",
    "        err_g_array =[]\n",
    "        err_r_array =[]\n",
    "        start_time = time.time()\n",
    "\n",
    "        if epoch !=0 and (epoch % decay_every == 0):\n",
    "            new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "            sess.run(tf.assign(lr_v, lr * new_lr_decay))\n",
    "            log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "            print(log)\n",
    "            # logging.debug(log)\n",
    "        elif epoch == 0:\n",
    "            log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "            print(log)\n",
    "\n",
    "        for step in range(n_batch_epoch):\n",
    "            step_time = time.time()\n",
    "            ## get matched text\n",
    "            idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "            b_real_caption = captions_ids_train[idexs]\n",
    "            b_real_caption = tl.prepro.pad_sequences(b_real_caption, padding='post')\n",
    "            ## get real image\n",
    "            b_real_images = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\n",
    "            # save_images(b_real_images, [ni, ni], 'samples/step1_gan-cls/train_00.png')\n",
    "            ## get wrong caption\n",
    "            idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "            b_wrong_caption = captions_ids_train[idexs]\n",
    "            b_wrong_caption = tl.prepro.pad_sequences(b_wrong_caption, padding='post')\n",
    "            ## get wrong image\n",
    "            idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\n",
    "            b_wrong_images = images_train[idexs2]\n",
    "            ## get noise\n",
    "            b_z = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "                # b_z = np.random.uniform(low=-1, high=1, size=[batch_size, z_dim]).astype(np.float32)\n",
    "\n",
    "            b_real_images = threading_data(b_real_images, prepro_img, mode='train')   # [0, 255] --> [-1, 1] + augmentation\n",
    "            b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\n",
    "            ## updates text-to-image mapping\n",
    "            if epoch < 50:\n",
    "                errRNN, _ = sess.run([rnn_loss, rnn_optim], feed_dict={\n",
    "                                                t_real_image : b_real_images,\n",
    "                                                t_wrong_image : b_wrong_images,\n",
    "                                                t_real_caption : b_real_caption,\n",
    "                                                t_wrong_caption : b_wrong_caption})\n",
    "            else:\n",
    "                errRNN = 0\n",
    "\n",
    "            ## updates D\n",
    "            errD, _ = sess.run([d_loss, d_optim], feed_dict={\n",
    "                            t_real_image : b_real_images,\n",
    "                            # t_wrong_image : b_wrong_images,\n",
    "                            t_wrong_caption : b_wrong_caption,\n",
    "                            t_real_caption : b_real_caption,\n",
    "                            t_z : b_z})\n",
    "            ## updates G\n",
    "            errG, _ = sess.run([g_loss, g_optim], feed_dict={\n",
    "                            t_real_caption : b_real_caption,\n",
    "                            t_z : b_z})\n",
    "\n",
    "            print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                        % (epoch, n_epoch, step, n_batch_epoch, time.time() - step_time, errD, errG, errRNN))\n",
    "            err_d_array.append(errD)\n",
    "            err_g_array.append(errG)\n",
    "            err_r_array.append(errRNN)\n",
    "            \n",
    "\n",
    "        if (epoch + 1) % print_freq == 0:\n",
    "            print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "            img_gen, rnn_out = sess.run([net_g.outputs, net_rnn.outputs], feed_dict={\n",
    "                                        t_real_caption : sample_sentence,\n",
    "                                        t_z : sample_seed})\n",
    "\n",
    "            # img_gen = threading_data(img_gen, prepro_img, mode='rescale')\n",
    "            save_images(img_gen, [ni, ni], 'samples/step1_gan-cls/train_{:02d}.png'.format(epoch))\n",
    "            \n",
    "        avg_err_d_array.append((sum(err_d_array)/ len(err_d_array)))\n",
    "        avg_err_g_array.append((sum(err_g_array)/len(err_g_array)))\n",
    "        avg_err_r_array.append((sum(err_g_array)/len(err_g_array)))\n",
    " \n",
    "    with open(\"_save_error.pickle\", 'wb') as f:\n",
    "        pickle.dump((avg_err_d_array,avg_err_g_array,avg_err_r_array), f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
